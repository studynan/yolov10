# 识别分为三个部分 数据处理 网络训练 网络使用。
需要用到的硬件为：d435i相机，单独的nuc来供识别使用（或加装gpu），装在无人机上的相机支架以及螺丝（见硬件部分）


## 第一部分，数据集处理
（数据集处理部分要注意的是，是使用的无人机还是无人车平台，因为两个平台的角度不同，导致训练网路所用的数据也不太相同）

### 数据的处理
  在比赛过程中，组委会所给出的数据较少，且角度单一，单单使用组委会数据是远远不够的，网络泛化性极差，故需要自己拍摄数据集
  拍摄数据集尽量选择多角度视频拍摄，拍摄过后可利用extract.py将视频帧提取出来为图片。
  将提取出的图片保存，利用pycharm中控制台picturelmb来对图片进行标注，标注格式为yolo，且最终呈现的数据格式为data所示
  最后将所有数据随机分配为70%train 15%vaild 15%test 用于后续的训练

## 第二部分，网路的训练
  （该部分要注意调整合适的训练速度）
  
### 网路训练具体步骤
   首先写好训练文件，详细见train.py,内部备注较易读懂
   租用合适的服务器，显存越大，训练速度越快，具体租用细节可联系昀皞
   调制train中的参数使得显存尽可能的充分利用。
   
### 1113.py文件是我们自己训练好的文件


## 第三部分，识别的使用
（由于主办方改了几次，故有三个版本）

### 第一个版本，识别与状态机通过话题通信
  yolo将检测到的物体，解算其中心距离图像中心的偏移量，将这些状态信息通过“object_detection_info”话题发布给状态机，使得状态机解算偏移量，发布后续任务
其中消息格式为a，x，y，z 分别代表a为是否有物体被识别到，xy为偏移量，z为是否保存。检测的详细逻辑见camera.py

### 第二个版本，两台电脑之间通过串口通信
  仅仅一台电脑同时视觉和规划，算力远远不够，掉帧掉很多，所以改用两个电脑
  communicate.py负责串口通信，camera负责识别，运行run.py
  
### 第三个版本，一台电脑单做识别，不需要通信
  上述两个方案都用的是时间延时来保证同一个物体不拍两次，这个方案使用编号追踪的方式，可以解决这个问题，运行cam2.py

  
  
